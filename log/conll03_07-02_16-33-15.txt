2025-07-02 16:33:15 - INFO: batch_size: 12
bert_hid_size: 1024
bert_learning_rate: 1e-05
bert_name: bert-large-cased
biaffine_size: 768
clip_grad_norm: 1.0
conv_dropout: 0.5
conv_hid_size: 96
dataset: conll03
dilation: [1, 2, 3]
dist_emb_size: 20
emb_dropout: 0.5
epochs: 10
ffnn_hid_size: 128
learning_rate: 0.001
lstm_hid_size: 768
out_dropout: 0.33
predict_path: output.json
save_path: ./model.pt
seed: 123
type_emb_size: 20
use_bert_last_4_layers: True
warm_factor: 0.1
weight_decay: 0
2025-07-02 16:33:15 - INFO: Loading Data
2025-07-02 16:33:24 - INFO: 
+---------+-----------+----------+
| conll03 | sentences | entities |
+---------+-----------+----------+
|  train  |     1     |    6     |
|   dev   |     1     |    1     |
|   test  |     1     |    2     |
+---------+-----------+----------+
2025-07-02 16:33:24 - INFO: Building Model
2025-07-02 16:33:28 - INFO: Epoch: 0
2025-07-02 16:33:30 - INFO: 
+---------+------+--------+-----------+--------+
| Train 0 | Loss |   F1   | Precision | Recall |
+---------+------+--------+-----------+--------+
|  Label  | nan  | 0.0000 |   0.0000  | 0.0000 |
+---------+------+--------+-----------+--------+
